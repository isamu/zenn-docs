---
title: "OpenAIã‚’TypeScriptã®Streamingã§ä½¿ã†ï¼“ã¤ã®æ–¹æ³•"
emoji: "ğŸš€"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [ChatGPT, LLM, Tech, OpenAI, SlashGPT]
published: true
publication_name: "singularity"
---

OpenAIãªã©ã®Streamingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹APIã‚’ä½¿ã†å ´åˆã®ï¼“ã¤ã®ä¾‹ã§ã™ã€‚

## ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿é–¢æ•°ã§ä½¿ã†ãã®ï¼‘
for of ã§loopã‚’å›ã™ã€‚
Streamã®çµæœã¯loopå†…ã§ã¨ã‚Œã‚‹ãŒã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿é–¢æ•°ã®çµæœã¯ã†ã‘ã¨ã‚Œãªã„ã€‚

```typescript
import "dotenv/config";
import OpenAI from "openai";

export async function *streamFunciton() {
  const openai = new OpenAI();

  const chatStream = await openai.beta.chat.completions.stream({
    messages: [{ role: "user", content: "æ—¥æœ¬ã®æ­´å²ã«ã¤ã„ã¦200æ–‡å­—ã§ã¾ã¨ã‚ã¦ãã ã•ã„" }],
    model: "gpt-3.5-turbo",
    stream: true,
  });

  for await (const message of chatStream) {
    const token = message.choices[0].delta.content;
    if (token) {
      yield token
    }
  }

  const chatCompletion = await chatStream.finalChatCompletion();
  return chatCompletion;
}


const main = async () => {
  for await (const token of streamFunciton()) {
    console.log(token);
  }
};

```

## ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿é–¢æ•°ã§ä½¿ã†ãã®2

ãã®ï¼‘ã¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿é–¢æ•°ã¨åŒã˜ã€‚ãŸã ã—ã€ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯ä½¿ã‚ãªã„ã§whileã§è‡ªåˆ†ã§å›ã™
{ done: true, value: result}ã§æœ€å¾Œã®çµæœãŒã¨ã‚Œã‚‹
å€‹äººçš„ã«ã¯letãŒå‡ºã¦ãã‚‹ã®ãŒæ°—ã«ãªã‚‹ã€‚

```typescript
import "dotenv/config";
import OpenAI from "openai";

export async function *streamFunciton() {
  const openai = new OpenAI();

  const chatStream = await openai.beta.chat.completions.stream({
    messages: [{ role: "user", content: "æ—¥æœ¬ã®æ­´å²ã«ã¤ã„ã¦200æ–‡å­—ã§ã¾ã¨ã‚ã¦ãã ã•ã„" }],
    model: "gpt-3.5-turbo",
    stream: true,
  });

  for await (const message of chatStream) {
    const token = message.choices[0].delta.content;
    if (token) {
      yield token
    }
  }

  const chatCompletion = await chatStream.finalChatCompletion();
  return chatCompletion;
}


const main = async () => {
  const generator = streamFunciton()
  let result = await generator.next();
  while (!result.done) {
    const value = await result.value;
    console.log(value)
    result = await generator.next();
  }
  console.log(JSON.stringify(result.value));

};
```


## ãã®ï¼“ callbackã‚’ä½¿ã†

Streaimngãƒ‡ãƒ¼ã‚¿ã¯callbackã§å—ã‘å–ã£ã¦ã€çµæœã¯é–¢æ•°ã®çµæœã¨ã—ã¦å—ã‘å–ã‚‹ã€‚
Streamingä¸è¦ãªå ´åˆã¯callbackã‚’æ¸¡ã•ãªã‘ã‚Œã°è‰¯ã„ã®ã§ã€ä½¿ã„åˆ†ã‘ã‚‹ã¨ãã‚‚æ¥½ã€‚

```typescript
export async function streamCallbackFunciton(callback: (token: string) => void) {
  const openai = new OpenAI();

  const chatStream = await openai.beta.chat.completions.stream({
    messages: [{ role: "user", content: "æ—¥æœ¬ã®æ­´å²ã«ã¤ã„ã¦200æ–‡å­—ã§ã¾ã¨ã‚ã¦ãã ã•ã„" }],
    model: "gpt-3.5-turbo",
    stream: true,
  });

  for await (const message of chatStream) {
    const token = message.choices[0].delta.content;
    if (token) {
      callback(token);
    }
  }

  const chatCompletion = await chatStream.finalChatCompletion();
  return chatCompletion;
}

const main = async () => {
  const callbackResult = await streamCallbackFunciton((token) => {
    console.log(token);
  });
  console.log(callbackResult);
  
};

main();

```

ãã®ã¾ã¾å‹•ãã‚³ãƒ¼ãƒ‰ã¯ã“ã¡ã‚‰ã€‚
https://github.com/isamu/samples/blob/master/typescript/streaming/generator.ts