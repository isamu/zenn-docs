---
title: "GraphAI - OpenAIã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§GraphAIã‚’å‘¼ã³å‡ºã™"
emoji: "ğŸ¤–"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: [agent, AI, LLM, Tech, GraphAI]
published: true
publication_name: "singularity"
---


`@receptron/graphai_express` `1.0.2` ã§ã€GraphAIã‚’OpenAIã®completionsäº’æ›ã®APIã¨ã—ã¦å‘¼ã³å‡ºã™middlewareã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚

ã©ã†ã„ã†ã“ã¨ã‹ã¨è¨€ã†ã¨ã€npmã‚„pythonã®OpenAIã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®`openai.chat.completions.create`ã‚„`openai.beta.chat.completions.stream`ã§GraphAIã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å‘¼ã³å‡ºã›ã‚‹ã€ã¨ã„ã†ã“ã¨ã§ã™ã€‚å¾Œè¿°ã™ã‚‹åˆ¶ç´„ãŒã‚ã‚Šã¾ã™ãŒã€æ—¢å­˜ã®LLMãƒ„ãƒ¼ãƒ«ã‹ã‚‰GraphAIã‚’ä½¿ã†ã“ã¨ãŒç°¡å˜ã«ãªã‚Šã¾ã™ã€‚

ã¾ãšã¯expressã®å®Ÿè£…ã®ã‚µãƒ³ãƒ—ãƒ«ã€‚

```TypeScript
import {
  completionRunner,
} from "@receptron/graphai_express";
import * as agents from "@graphai/agents";

const agentDictionary: AgentFunctionInfoDictionary = agents;

const model2graphData = (__model: string) => {
  const graphData = {
    version: 0.5,
    nodes: {
      messages: {
        value: [],
      },
      llm: {
        agent: "openAIAgent",
        params: {
          stream: true,
          isResult: true,
        },
        inputs: {
          messages: ":messages",
        },
        isResult: true,
      },
    },
  };
  return graphData;
};

const onLogCallback = (log: TransactionLog, __isUpdate: boolean) => {
  console.log(log);
};

app.post("/api/chat/completions", completionRunner(agentDictionary, model2graphData, [], onLogCallback));

```

åŸºæœ¬çš„ã«ã¯ã€`completionRunner`ã‚’middlewareã«è¿½åŠ ã™ã‚‹ã ã‘ã€‚`agentDictionary`ã¯agents, `model2graphData`ã¯modelã‚’GraphDataã«å¤‰æ›ã™ã‚‹é–¢æ•°ã€‚ä»Šå›ã¯ã‚µãƒ³ãƒ—ãƒ«ãªã®ã§æ±ºã‚æ‰“ã¡ã§ã™ãŒå®Ÿéš›ã«ã¯modelã¨å¯¾å¿œã™ã‚‹GraphDataã‚’è¿”ã—ã¾ã™ã€‚GraphAIã§ã¯ã€llmã®modelã¯GraphDataã®ä¸­ã§æŒ‡å®šã™ã‚‹ã®ã§ã€completionsã§æ¸¡ã•ã‚Œã‚‹model(requred)ã¯ã€graphDataã‚’æŒ‡å®šã™ã‚‹ãŸã‚ã«ä½¿ã†ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚


OpenAIã®tsã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¯ä»¥ä¸‹

- apiKeyã¯ä¸è¦ã ãŒã€æŒ‡å®šã—ãªã„ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã§dummyã‚’è¿½åŠ ã€‚
- baseURLã¯GraphAI/completionRunnerã®ã‚µãƒ¼ãƒã‚’æŒ‡å®šã€‚ã“ã‚Œã‚’prefixã¨ã—ã¦ã€/chat/completionsã‚’è¿½åŠ ã—ãŸendpointã‚’å‘¼ã¶
- messagesã¯openai(GraphAI)ã®messageå½¢å¼ã§å±¥æ­´(ã‚·ã‚¹ãƒ†ãƒ ã€ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ã„ã‚Œã‚‹ã€‚
- openai.beta.chat.completions.streamã‚’ä½¿ã£ã¦å‘¼ã³å‡ºã™

ä»¥ä¸Šã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚

```TypeScript
import OpenAI from "openai";

const openai = new OpenAI({
  baseURL: "http://localhost:8085/api",
  apiKey: "dummy",
});

const messages = [
  {
    role: "user",
    content: [
      {
        type: "text",
        text: "How can I travel to Mars?",
      },
    ],
  },
] as any;
async function main() {
  const stream = await openai.beta.chat.completions.stream({
    model: "gpt-4o",
    messages,
  });

  for await (const chunk of stream) {
    const token = chunk.choices[0]?.delta?.content;
    if (token) process.stdout.write(token);
  }
  console.log("\n--- done ---");
  const chatCompletion = await stream.finalChatCompletion();
  console.log(JSON.stringify(chatCompletion, null, 2));

}

main().catch(console.error);
```

openAIã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨ã—ã¦ä½¿ã†ã®ã§åˆ¶ç´„ã‚ã‚Šã€‚

- messagesã‚’POSTã—ã¦assistantã®messageï¼ˆçµæœã‚’å—ã‘å–ã‚‹ï¼‰
- POSTã•ã‚ŒãŸmessagesã‚’GraphDataã®messagesã«injectionã™ã‚‹ã®ã§ã€messagesã®static nodeã¯å¿…é ˆ
  - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰POSTã§ãã‚‹ã‚‚ã®ï¼ˆæ¸¡ã›ã‚‹ã‚‚ã®)ã¯messagesã ã‘ã«ãªã‚‹ã€‚
- GraphDataã§è¤‡é›‘ãªå‡¦ç†ã‚’ã™ã‚‹ã“ã¨ã¯å¯èƒ½ã€‚ãŸã ã—çµæœã¨ã—ã¦å—ã‘å–ã‚Œã‚‹ã®ã¯ï¼‘ã¤ã®messageã ã‘ã€‚
- Streamingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãŒã€openAIã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆ¶ç´„ã§ï¼‘ã¤ã®llm(Agent)ã®çµæœã—ã‹ã†ã‘ã¨ã‚Œãªã„
  - ä¸¦åˆ—ã§streamingã™ã‚‹ã¨æ··ã–ã£ãŸçµæœã¨ãªã‚‹
  - ã‚·ãƒªã‚¢ãƒ«ã®å ´åˆã¯ã€ãŸã¶ã‚“ï¼’ã¤é€£çµã—ãŸçµæœã¨ãªã‚‹ã¯ãš
- loopå‡¦ç†ã‚’ã™ã‚‹å ´åˆã¯ã€completionsã‚’å‘¼ã³å‡ºã—ãŸçµæœ + user promptã‚’messagesã«å…¥ã‚Œã¦å†åº¦postã™ã‚Œã°ã‚ˆã„